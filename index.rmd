---
title: "Using Keras to detect activity"
author: "Nick Strayer"
date: "7/1/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Libraries

```{r}
library(keras)
library(tidyverse)
library(knitr)
```

## The data

The data come from the [Smartphone-Based Recognition of Human Activities and Postural Transitions Data Set ](http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions) distributed by the University of California, Irvine. 

The main datasource when downloaded from the link above contains two different 'parts' of the data. One that has been pre-processed using various feature extraction techniques such as fast fourier transform, and another `RawData` section that simply supplies the raw X,Y,Z directions of an accelerometer and gyroscope. This is the dataset we will use. 

__The labels__

The data has integer encodings for the activities which, while not important to the model itself, are helpful for use to see. Let's load them first. 

```{r}
activityLabels <- read.table('data/activity_labels.txt') %>% 
  rename(number = V1, label = V2)

activityLabels %>% kable()
```

Next we will load in the labels key for the `RawData`. The key for the columns is taken from the data `README.txt`. 

```
Column 1: experiment number ID, 
Column 2: user number ID, 
Column 3: activity number ID 
Column 4: Label start point (in number of signal log samples (recorded at 50Hz))
Column 5: Label end point (in number of signal log samples)
```

```{r}
labels <- read.table('data/RawData/labels.txt') %>% 
  rename(
    experiment = V1,
    userId = V2,
    activity = V3,
    startPos = V4,
    endPos = V5
  )

labels %>% 
  head() %>% 
  kable()
```

Next, let's look at the actual files of the user data provided to us in `RawData/`

```{r}
dataFiles <- list.files('data/RawData')

dataFiles %>% head()
```

So we have a three-part file naming scheme. The first is the type of data the file contains: either `acc` for accelerometer or `gyro` for gyroscope. Next is the experiment number, and last is the user Id for the recording. Let's load these into a dataframe for ease of use later. 

```{r}
fileInfo <- data_frame(
  filePath = dataFiles
) %>%
  filter(filePath != 'labels.txt') %>% 
  separate(filePath, sep = '_', into = c('type', 'experiment', 'userId'), remove = FALSE) %>% 
  mutate(
    experiment = str_remove(experiment, 'exp'),
    userId = str_remove_all(userId, 'user|\\.txt')
  ) %>% 
  spread(type, filePath)

fileInfo %>% head() %>% kable()
```

```{r}
# Read contents of single file to a dataframe with accelerometer and gyro data.
readInData <- function(experiment, userId){
  genFilePath = function(type){
    return(paste0('data/RawData/', type, '_exp',experiment, '_user', userId, '.txt'))
  }  
  
  bind_cols(
    read.table(genFilePath('acc'), col.names = c('a_x', 'a_y', 'a_z')),
    read.table(genFilePath('gyro'), col.names = c('g_x', 'g_y', 'g_z'))
  )
}

# Function to read a given file and get the observations contained along with their classes.
loadFileData <- function(curExperiment, curUserId){
  # load sensor data from file into dataframe
  allData <- readInData(curExperiment, curUserId)

  extractObservation <- function(startPos, endPos){
    allData[startPos:endPos,]
  }
  
  # get observation locations in this file from labels dataframe
  dataLabels <- labels %>% 
    filter(userId == as.integer(curUserId), experiment == as.integer(curExperiment))
  

  # extract observations as dataframes and save as a column in dataframe.
  dataLabels %>% 
    mutate(
      data = map2(startPos, endPos, extractObservation)
    ) %>% 
    select(-startPos, -endPos)
}

allObservations <- map2_df(fileInfo$experiment, fileInfo$userId, loadFileData)

allObservations %>% head()
```

So now that we have all the data loaded and our labels as either `experiment`, `userId`, or `activity` we can explore the dataset. 

Before we do so, however, we need to set aside a testing set of observations that we won't look at until after we have trained our model in an attempt to get the least-biased view of our performance. 

We will leave out 20% of the data for this purpose, making sure that no user is in both the train and testing data (in an effort see how generalizable our model is to new users.)

### Train Test Split




